{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa13918a",
   "metadata": {},
   "source": [
    "##### ScholarAgent: Basic RAG Pipeline Test    \n",
    "**Objective:** Test the core RAG pipeline to ensure it can retrieve context from our vector store and generate a relevant answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff83328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd99d3a6",
   "metadata": {},
   "source": [
    "##### Create the RAG Chain\n",
    "This function call will initialize the vector store, the embedding model, the prompt, and the Gemini LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58de9bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 01:57:22,819 - src.rag_pipeline.core - INFO - Creating the RAG chain...\n",
      "/workspaces/scholar-agent/src/rag_pipeline/core.py:38: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = SentenceTransformerEmbeddings(\n",
      "/workspaces/scholar-agent/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspaces/scholar-agent/src/rag_pipeline/core.py:41: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(\n",
      "2025-08-29 01:57:30,034 - src.rag_pipeline.core - INFO - Retriever created successfully.\n",
      "2025-08-29 01:57:30,035 - src.rag_pipeline.core - INFO - Prompt template created.\n",
      "2025-08-29 01:57:30,050 - src.rag_pipeline.core - INFO - LLM initialized with model: gemini-1.5-flash\n",
      "2025-08-29 01:57:30,050 - src.rag_pipeline.core - INFO - RAG chain created successfully.\n"
     ]
    }
   ],
   "source": [
    "from src.rag_pipeline.core import create_rag_chain\n",
    "\n",
    "rag_chain = create_rag_chain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb4d57",
   "metadata": {},
   "source": [
    "##### Define our Test Question\n",
    "This question is designed to be complex and specific to the papers we ingested, requiring the model to synthesize information rather than just find a single keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731b05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question = \"According to Anthropic's research, what is the core problem with polysemantic neurons, \" \\\n",
    "\"and how does their dictions learning approach with sparse autoencoders attempt to solve it by finding\" \\\n",
    "\"more monosemantic features?\"\n",
    "\n",
    "simple_query = \"What is polysemanticity?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a56b24",
   "metadata": {},
   "source": [
    "##### Invoke the Chain and Get a Response\n",
    "We pass our question to the chain and print the generated answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8fef689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking RAG chain ...\n",
      "\n",
      " ~~~~~~~~~~~~~~ Generated Answer ~~~~~~~~~~~~~~~\n",
      "Polysemanticity is when neurons respond to multiple unrelated inputs, complicating function assignment.\n"
     ]
    }
   ],
   "source": [
    "print(\"Invoking RAG chain ...\")\n",
    "response = rag_chain.invoke(simple_query)\n",
    "print(\"\\n ~~~~~~~~~~~~~~ Generated Answer ~~~~~~~~~~~~~~~\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
